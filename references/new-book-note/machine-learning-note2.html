
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>有监督学习 1-3 &#8212; ml-basic</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ml-basic/references/new-book-note/machine-learning-note2';</script>
    <link rel="canonical" href="/ml-basic/references/new-book-note/machine-learning-note2.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="ml-basic - Home"/>
    <img src="../../../_static/logo.png" class="logo__image only-dark pst-js-only" alt="ml-basic - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../README.html">
                    Machine Learning Algorithms Guide
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../books/Chapter1.html">机器学习概要</a></li>


<li class="toctree-l1"><a class="reference internal" href="../books/Chapter2.html">2.有监督学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books/Chapter3.html">3.无监督学习</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books/Chapter4.html">第四章 评估方法和各种数据的处理</a></li>



<li class="toctree-l1"><a class="reference internal" href="../books/Iris.html">实践应用：</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books/jupyter_use.html">jupyter 入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books/LSA.html">例子：简单文档集合的 LSA 处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books/PCA.html">步骤 1: 数据标准化</a></li>




<li class="toctree-l1"><a class="reference internal" href="../books/VisibleTools.html">Matplotlib</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fml-basic/references/new-book-note/machine-learning-note2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/ml-basic/references/new-book-note/machine-learning-note2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>有监督学习 1-3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">有监督学习 1-3</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">算法一：线性回归</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">算法说明</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">线性回归代码演示</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">安斯库姆四重奏</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">最小化均方误差</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">其它线性回归和非线性回归</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">算法二：正则化</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">算法说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">岭回归的误差函数</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">损失函数最小化</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">示例代码</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso回归</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">算法三：逻辑回归</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">算法说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">与线性回归进行比较：</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">示例代码</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">特征</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>有监督学习 1-3<a class="headerlink" href="#id1" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id2">
<h1>算法一：线性回归<a class="headerlink" href="#id2" title="Link to this heading">#</a></h1>
<section id="id3">
<h2>概述<a class="headerlink" href="#id3" title="Link to this heading">#</a></h2>
<p>线性回归很常见，简单带过，就是把xy对应数据拟合成线性关系。</p>
<p>对于直线方程，有 <span class="math notranslate nohighlight">\(y = kx +b\)</span>，其中有两个参数也就是k和b分别是斜率和截距。</p>
<ul class="simple">
<li><p>学习参数：算法学得的参数例如斜率k和截距b。</p></li>
<li><p>一元回归：指的是只有一个特征变量的情况，即模型只使用一个自变量去预测目标变量。</p></li>
</ul>
</section>
<section id="id4">
<h2>算法说明<a class="headerlink" href="#id4" title="Link to this heading">#</a></h2>
<p>线性回归中，需要从不在一条直线上的点求出直线。为了判断学习参数的优劣性，使用均方误差进行判断。</p>
<p>均方误差：每个目标变量与直线的差值平方和</p>
<p><span class="math notranslate nohighlight">\(\frac{1}{n} \sum_{i=1}^{n} \left[ y_i - (b + k x_i) \right]^2\)</span></p>
<p>均方误差越小，越能更好的表示数据关联性。</p>
<ul class="simple">
<li><p>误差函数：能表明学习参数和误差之间的关系的函数，例如此处的均方误差。</p></li>
</ul>
</section>
<section id="id5">
<h2>线性回归代码演示<a class="headerlink" href="#id5" title="Link to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">10.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">8.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">13.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">11.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">14.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">12.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">5.0</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.04</span><span class="p">,</span> <span class="mf">6.95</span><span class="p">,</span> <span class="mf">7.58</span><span class="p">,</span> <span class="mf">8.81</span><span class="p">,</span> <span class="mf">8.33</span><span class="p">,</span> <span class="mf">9.96</span><span class="p">,</span> <span class="mf">7.24</span><span class="p">,</span> <span class="mf">4.26</span><span class="p">,</span> <span class="mf">10.84</span><span class="p">,</span> <span class="mf">4.82</span><span class="p">,</span> <span class="mf">5.68</span><span class="p">]</span>
<span class="c1"># 划分训练集和测试集，test_size 指定测试集的比例</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span> <span class="c1"># 截距</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span> <span class="c1"># 斜率</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="c1"># 对x=0, x=1的预测结果</span>
<span class="c1"># 绘制数据集散点图</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="c1"># 绘制回归线</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Linear Regression Model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="1.png" src="ml-basic/references/new-book-note/pic%5C1.png" /></p>
</section>
<section id="id6">
<h2>详细说明<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<section id="id7">
<h3>安斯库姆四重奏<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p><strong>安斯库姆四重奏</strong>（Anscombe’s Quartet）是一组由统计学家弗朗西斯·安斯库姆（Francis Anscombe）在 1973 年提出的数据集。它由四组不同的数据构成，尽管这些数据在许多统计属性上（如均值、方差、相关系数、线性回归直线等）非常相似，但它们的分布形态却大不相同。</p>
<p><img alt="2.png" src="ml-basic/references/new-book-note/pic/pic/2.png" /></p>
<p>以上的四组数据线性回归直线完全一致，但我们明显可以发现有部分的数据并不适合这样拟合。</p>
<p>对原本不遵循线性分布的数据强行进行线性回归也得不到好的结果。拿到数据之后，首先应该进行可视化，再考虑是否进行线性回归。</p>
</section>
<section id="id8">
<h3>最小化均方误差<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>均方误差可以使用学习参数的函数表示：</p>
<p><span class="math notranslate nohighlight">\(L(w_0, w_1) = \frac{1}{n} \sum_{i=1}^{n} \left[ y_i - (b + k x_i) \right]^2\)</span></p>
<p>此时代入xi yi，这里使用以下值作为例子</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>i</p></th>
<th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>3</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>6</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>7</p></td>
<td><p>7</p></td>
</tr>
</tbody>
</table>
</div>
<p>可以得到以下 <span class="math notranslate nohighlight">\(L(b, k) = \frac{1}{4} \sum_{i=1}^{4} \left[ y_i - (b + k x_i) \right]^2 = b^2 + 24.5k^2 + 9b k - 8b - 42k + 21\)</span> 由此二次函数可得图像（w0=b，w1=k）：</p>
<p><img alt="3.png" src="ml-basic/references/new-book-note/pic/3.png" /></p>
<p>可以发现a点是最佳学习参数</p>
</section>
<section id="id9">
<h3>其它线性回归和非线性回归<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>一元回归：指独立特征变量只有一个时的线性回归。</p></li>
<li><p>多元回归：当特征变量有两个及以上时，称作多元回归。</p></li>
<li><p>多项式回归：包含特征变量的多次方项的线性回归。</p></li>
<li><p>非线性回归：例如e的kx次，学习参数和目标变量不是线性关系，被分为非线性回归。</p></li>
</ul>
<p>是否为线性回归不是从特征变量来看的。从学习参数的角度来看是线性的回归才称为线性回归，所以多项式回归也属于线性回归。</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id10">
<h1>算法二：正则化<a class="headerlink" href="#id10" title="Link to this heading">#</a></h1>
<section id="id11">
<h2>概述<a class="headerlink" href="#id11" title="Link to this heading">#</a></h2>
<p>正则化是防止过拟合的一种方法，与线性回归等算法配合使用。通过向损失函数增加惩罚项的方式对模型施加制约，有望提高模型的泛化能力。</p>
<ul class="simple">
<li><p>过拟合：模型在验证数据上的误差比训练数据的误差大得多的现象</p></li>
<li><p>泛化程度：机器学习模型在新数据上的表现能力，具体来说是模型能否在训练集之外的数据上取得良好的性能。</p></li>
</ul>
<p>（其中的一个原因：模型复杂度过高）</p>
<p>对于以下例子，数据是y = sin(2pi x)，使用多次进行线性回归。</p>
<p><img alt="4.png" src="ml-basic/references/new-book-note/pic%5C4.png" /></p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>次数</p></th>
<th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>0.412</p></td>
<td><p>0.618</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>0.176</p></td>
<td><p>0.193</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>0.081</p></td>
<td><p>0.492</p></td>
</tr>
<tr class="row-odd"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
<tr class="row-even"><td><p>6</p></td>
<td><p>0.024</p></td>
<td><p>3.472</p></td>
</tr>
</tbody>
</table>
</div>
<p>我们可以发现第六次线性回归的误差值是最小的，但是验证误差十分大，这就是一个过拟合的例子，六次线性回归的模型太过复杂，由于过拟合导致泛化程度低。</p>
<p>应用正则化后就会抑制模型复杂度，防止后期的过拟合。</p>
</section>
<section id="id12">
<h2>算法说明<a class="headerlink" href="#id12" title="Link to this heading">#</a></h2>
<p>岭回归（Ridge Regression）是一种线性回归的改进方法，常用于解决多重共线性问题（即解释变量之间高度相关）和防止模型过拟合。</p>
<p>之所以复杂模型会出现过拟合：学习参数值太大或太小。</p>
<p>随着学习此处的增加，学习参数的绝对值会变大，但使用了正则化则会减少这种情况。</p>
<section id="id13">
<h3>岭回归的误差函数<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>考虑对二次线性回归应用正则化的情况：</p>
<p><span class="math notranslate nohighlight">\(R(w) = \sum_{i=1}^{m} \left[ y_i - (w_0 + w_1 x_i + w_2 x_i^2) \right]^2 + \alpha (w_1^2 + w_2^2)\)</span></p>
<p>第1项 <span class="math notranslate nohighlight">\(\sum_{i=1}^{m} \left[ y_i - (w_0 + w_1 x_i + w_2 x_i^2) \right]^2\)</span> 是线性回归的损失函数。</p>
<p>第2项 <span class="math notranslate nohighlight">\(\alpha (w_1^2 + w_2^2)\)</span> 被称为惩罚项（或者正则化项），是学习参数的平方和的形式。</p>
<p>一般来说，惩罚项中不包含截距。</p>
<p>α控制了正则化强度，α越大，对学习参数的抑制就越强。</p>
</section>
<section id="id14">
<h3>损失函数最小化<a class="headerlink" href="#id14" title="Link to this heading">#</a></h3>
<p>岭回归的误差函数就是在后面加上了惩罚项，距我们之前所说，造成过拟合的原因是w值的绝对值过大，因此如果w值的绝对值过大，就增加惩罚项，从而避免过拟合。</p>
<p>用于抑制学习参数。</p>
</section>
<section id="id15">
<h3>示例代码<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p>对sin函数进行岭回归建模</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">train_size</span><span class="p">)</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">test_size</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">train_X</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">train_size</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">test_X</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">test_size</span><span class="p">)</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>  <span class="c1"># 次数为6</span>
<span class="n">train_poly_X</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">test_poly_X</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test_X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_poly_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">train_pred_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_poly_X</span><span class="p">)</span>
<span class="n">test_pred_y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_poly_X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train_pred_y</span><span class="p">,</span> <span class="n">train_y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_pred_y</span><span class="p">,</span> <span class="n">test_y</span><span class="p">))</span>
<span class="c1"># 0.2525090370132518</span>
<span class="c1"># 0.34030978733484846</span>
</pre></div>
</div>
</section>
</section>
<section id="id16">
<h2>详细说明<a class="headerlink" href="#id16" title="Link to this heading">#</a></h2>
<p>控制α来调整正则化强度，应一边验证误差一边对α进行调整，最终得到合适的α。</p>
<section id="lasso">
<h3>Lasso回归<a class="headerlink" href="#lasso" title="Link to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(R(w) = \sum_{i=1}^{n} \left[ y_i - (w_0 + w_1 x_i + w_2 x_i^2) \right] + \alpha (|w_1| + |w_2|)\)</span></p>
<p>Lasso 回归的惩罚项是学习参数的绝对值之和，这一点与岭回归不同。</p>
<p><img alt="5.png" src="ml-basic/references/new-book-note/pic%5C5.png" /></p>
<p>绿色是误差函数，蓝色是惩罚项。</p>
<p>如Lasso 回归所示，具有学习参数容易变为0的特点。利用这个特点，我们可以使用学习参数不为0的特征来构建模型，从而达到利用Lasso回归选择特征的效果。这样不仅能提高模型的泛化能力，还能使模型的解释变容易。</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id17">
<h1>算法三：逻辑回归<a class="headerlink" href="#id17" title="Link to this heading">#</a></h1>
<section id="id18">
<h2>概述<a class="headerlink" href="#id18" title="Link to this heading">#</a></h2>
<p>逻辑回归是一种用于有监督学习的分类任务的简单算法。逻辑回归通过计算数据属于各类别的概率来进行分类。利用这个概率，可以对某个事件发生或不发生进行二元分类（也可以三元以上分类）</p>
<p>这次的例子是，给定100天里，温度对应是否有积雪的情况，y轴为0时有积雪，为1无积雪。</p>
<p>x轴是摄氏度气温，可以看到高温没积雪，低温有积雪。</p>
<p><img alt="6.png" src="ml-basic/references/new-book-note/pic%5C6.png" /></p>
<p>上图是对数据的逻辑回归，在0度的时候是12%，1度50%，2度88%。</p>
</section>
<section id="id19">
<h2>算法说明<a class="headerlink" href="#id19" title="Link to this heading">#</a></h2>
<p>逻辑回归根据数据x和表示其所属类别的标签y进行学习，计算概率。</p>
<p>如果标签是二元分类，则可以使用前面的y=0, 1这种二元数值表示。</p>
<section id="id20">
<h3>与线性回归进行比较：<a class="headerlink" href="#id20" title="Link to this heading">#</a></h3>
<p>相同点：基本思想，对数据x乘以权重向量w，再加上偏置w0，计算wT x+w0的值</p>
<p>不同点：逻辑回归的输出范围限制在01之间，使用了Sigmoid函数：</p>
<p>σ(z)=1/[1+exp(-z)]</p>
<p>对输入数据x使用Sigmoid函数，p=σ(wT x+w0) 得到标签为y的概率p。（二元分类使用0.5作为阈值）</p>
<p>误差函数使用逻辑损失。逻辑损失在分类失败时返回大值，在分类成功时为小值。</p>
<p>与在误差回归中引入的均方误差不同的是，我们无法通过式子变形来计算逻辑损失的最小值，因此需要采用梯度下降法通过数值计算来求解。（机器学习中经常会通过数值计算来近似求解）</p>
</section>
</section>
<section id="id21">
<h2>示例代码<a class="headerlink" href="#id21" title="Link to this heading">#</a></h2>
<p>以下代码就是对之前温度和积雪预测的实例，最后输出了各种概率。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]])[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="c1">#  array([ 0.12082515,  0.50296844,  0.88167486])</span>
</pre></div>
</div>
</section>
<section id="id22">
<h2>详细说明<a class="headerlink" href="#id22" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>决策边界：逻辑回归计算出来概率正好为50%的位置</p></li>
</ul>
<p>决策边界的形状因使用的算法不同而有很大的不同。在平面的情况下，逻辑回归的决策边界是直线。其它算法的决策边界会更复杂</p>
<section id="id23">
<h3>特征<a class="headerlink" href="#id23" title="Link to this heading">#</a></h3>
<p><strong>如何通过逻辑回归模型中的特征权重（系数）来理解每个特征对分类结果的影响</strong>。</p>
<p>在逻辑回归中，每个特征（比如鸢尾花的花瓣长、花瓣宽等）都有一个权重值。权重的<strong>符号</strong>（正或负）和大小告诉我们该特征对分类结果的影响：</p>
<ul class="simple">
<li><p><strong>正的权重</strong>：如果这个特征值增加，模型认为该数据属于目标类别的概率（这里是杂色鸢尾）就越大。</p></li>
<li><p><strong>负的权重</strong>：如果这个特征值增加，模型认为该数据属于目标类别的概率反而会降低。</p></li>
</ul>
<p>举个例子，这里用的是鸢尾花的数据，分类目标是预测一朵花是“杂色鸢尾”（versicolor）还是“山鸢尾”（setosa）。两个特征“花瓣长度”（petal length）和“萼片宽度”（sepal width）分别有正的和负的权重：</p>
<ol class="arabic simple">
<li><p><strong>花瓣长度的权重是正的</strong>，表示如果花瓣长度越长，模型就越倾向于把这朵花分类为杂色鸢尾。</p></li>
<li><p><strong>萼片宽度的权重是负的</strong>，表示如果萼片宽度越小，模型就越倾向于把这朵花分类为杂色鸢尾。</p></li>
</ol>
<p>这样，通过查看权重的符号和大小，我们能直观地理解每个特征对分类结果的影响方向和程度。</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ml-basic\references\new-book-note"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">有监督学习 1-3</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">算法一：线性回归</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">算法说明</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">线性回归代码演示</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">安斯库姆四重奏</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">最小化均方误差</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">其它线性回归和非线性回归</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">算法二：正则化</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">算法说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">岭回归的误差函数</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">损失函数最小化</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">示例代码</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">Lasso回归</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">算法三：逻辑回归</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id18">概述</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id19">算法说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id20">与线性回归进行比较：</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id21">示例代码</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id22">详细说明</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id23">特征</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>